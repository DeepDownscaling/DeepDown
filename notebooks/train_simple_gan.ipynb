{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721a1923-df03-4ace-a939-8a62df36c1a8",
   "metadata": {},
   "source": [
    "# Precipitation and temperature downscaling using GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a4c7b-f424-4168-87db-fb4c421e81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=10)\n",
    "mpl.rc('xtick', labelsize=8)\n",
    "mpl.rc('ytick', labelsize=8)\n",
    "\n",
    "# Utils\n",
    "from deepdown.utils.data_loader import *\n",
    "from deepdown.utils.utils_plot import *\n",
    "from deepdown.utils.utils_loss import *\n",
    "from deepdown.utils.helpers import *\n",
    "from deepdown.utils.data_generators import *\n",
    "from deepdown.models.SRGAN import *\n",
    "\n",
    "# Try dask.distributed and see if the performance improves...\n",
    "from dask.distributed import Client\n",
    "c = Client(n_workers=os.cpu_count()-2, threads_per_worker=1)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"divide by zero encountered in divide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec53edd-fea4-4a06-86cf-9759b3e91883",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cuda_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6a454-bf5b-408c-949a-fe32115d6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and constant\n",
    "with open('../config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# Paths\n",
    "PATH_DEM = config['PATH_DEM']\n",
    "PATH_ERA5_025 = config['PATH_ERA5_025']  # Original ERA5 0.25°\n",
    "PATH_ERA5_100 = config['PATH_ERA5_100']  # ERA5 1°\n",
    "PATH_MCH = config['PATH_MeteoSwiss']  # Note that Meteoswiss has a different coordinate system, but it doesn't matter here, as we only care about tensors\n",
    "PATH_TMP = config['PATH_TMP']\n",
    "\n",
    "# Data options\n",
    "DATE_START = '1999-01-01'  # '1979-01-01'\n",
    "DATE_END = '2021-12-31'\n",
    "YY_TRAIN = [1999, 2015]  # [1979, 2015]\n",
    "YY_TEST = [2016, 2021]\n",
    "LEVELS = [850,1000] #[300, 500, 700, 850, 1000]  # Available with CORDEX-CMIP6\n",
    "RESOL_LOW = 0.25  # degrees\n",
    "INPUT_VARIABLES = ['tp', 't']\n",
    "INPUT_PATHS = [PATH_ERA5_025 + '/precipitation', PATH_ERA5_025 + '/temperature']\n",
    "DUMP_DATA_TO_PICKLE = True\n",
    "\n",
    "# Crop on a smaller region\n",
    "DO_CROP = True\n",
    "# I reduce the area of crop now, to avoid NA\n",
    "CROP_X = [2700000, 2760000]  # with NAN: [2720000, 2770000]\n",
    "CROP_Y = [1190000, 1260000]  # with NAN: [1290000, 1320000]\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Display options\n",
    "PLOT_DATA_FULL_EXTENT = False\n",
    "PLOT_DATA_CROPPED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd263aa1-8933-46db-bd91-c47d88c5b17b",
   "metadata": {},
   "source": [
    "## Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11a81f-dcc9-4819-b3b0-ad33ea8cf928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target data\n",
    "target = load_target_data(DATE_START, DATE_END, PATH_MCH, PATH_TMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab299048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the axes of the final target domain based on temperature \n",
    "x_axis = target.TabsD.x\n",
    "y_axis = target.TabsD.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85a0efe-4957-4652-87b1-e6c9224e0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_DATA_FULL_EXTENT:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,5))\n",
    "    plot_map(axs[0], target.RhiresD.mean(dim='time').to_numpy().squeeze(), title=\"Daily precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[1], target.TabsD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[2], target.TmaxD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Maximum temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], target.TminD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Minimum temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e696c2",
   "metadata": {},
   "source": [
    "## Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = load_input_data(DATE_START, DATE_END, PATH_DEM, INPUT_VARIABLES, INPUT_PATHS, \n",
    "                             LEVELS, RESOL_LOW, x_axis, y_axis, PATH_TMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53bbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_DATA_FULL_EXTENT:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,5))\n",
    "    plot_map(axs[0], input_data.topo.to_numpy().squeeze(), title=\"Topography\", cmap=mpl.cm.terrain)\n",
    "    plot_map(axs[1], input_data.tp.mean(dim='time').to_numpy().squeeze(), title=\"Input precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[2], input_data.t.sel(level=850).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 850hPa\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], input_data.t.sel(level=1000).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 1000hPa\", cmap=mpl.cm.RdBu_r)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68469053-d1f8-4733-ab88-ce5922bcf55d",
   "metadata": {},
   "source": [
    "## Crop domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ff05a-9d5d-436b-bca2-36d9f8d2be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CROP:\n",
    "    input_data = input_data.sel(x=slice(min(CROP_X), max(CROP_X)), y=slice(max(CROP_Y), min(CROP_Y)))\n",
    "    target = target.sel(x=slice(min(CROP_X), max(CROP_X)), y=slice(max(CROP_Y), min(CROP_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee82ad1-2270-4792-9be2-d6b7ab93a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CROP and PLOT_DATA_CROPPED:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,4))\n",
    "    plot_map(axs[0], target.RhiresD.mean(dim='time').to_numpy().squeeze(), title=\"Daily precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[1], target.TabsD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[2], target.TmaxD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Maximum temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], target.TminD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Minimum temperature\", cmap=mpl.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e606d-f05c-4b7a-8ad8-45ba02f58e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CROP and PLOT_DATA_CROPPED:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,4))\n",
    "    plot_map(axs[0], input_data.topo.to_numpy().squeeze(), title=\"Topography\", cmap=mpl.cm.terrain)\n",
    "    plot_map(axs[1], input_data.tp.mean(dim='time').to_numpy().squeeze(), title=\"Input precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[2], input_data.t.sel(level=850).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 850hPa\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], input_data.t.sel(level=1000).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 1000hPa\", cmap=mpl.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e275c8-038a-4012-bb9a-3783af9a0d7d",
   "metadata": {},
   "source": [
    "## Split sample and data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9046d4-1db6-44ba-947b-e82198696de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train = input_data.sel(time=slice('1999', '2011')) \n",
    "x_valid = input_data.sel(time=slice('2012', '2015')) \n",
    "x_test = input_data.sel(time=slice('2016', '2021'))\n",
    "\n",
    "y_train = target.sel(time=slice('1999', '2011'))\n",
    "y_valid = target.sel(time=slice('2012', '2005'))\n",
    "y_test = target.sel(time=slice('2006', '2011'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe836e2-e95d-4540-a7b2-198459a1b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables to use as input and output\n",
    "input_vars = {'topo' : None, 'tp': None, 't': LEVELS}\n",
    "output_vars = ['RhiresD', 'TabsD'] #['RhiresD', 'TabsD', 'TmaxD', 'TminD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27464664-a9c9-431a-97ec-ff51a8961df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = DataGenerator(x_train, y_train, input_vars, output_vars)\n",
    "loader_train = torch.utils.data.DataLoader(training_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3bcd8-b6f7-4d1d-9fca-42d7ae7b4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "valid_set = DataGenerator(x_valid, y_valid, input_vars, output_vars, shuffle=False, mean=training_set.mean, std=training_set.std)\n",
    "loader_val = torch.utils.data.DataLoader(valid_set, batch_size=32)\n",
    "\n",
    "# Test\n",
    "test_set = DataGenerator(x_test, y_test, input_vars, output_vars, shuffle=False, mean=training_set.mean, std=training_set.std)\n",
    "loader_test = torch.utils.data.DataLoader(test_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdb8e7-0119-4d6f-a7c9-6266c9db0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure the range on the input and output images is correct, and they're the correct shape\n",
    "testx, testy = training_set.__getitem__(3)\n",
    "print(\"x shape: \", testx.shape)\n",
    "print(\"y shape: \", testy.shape)\n",
    "print(\"x min: \", torch.min(testx))\n",
    "print(\"x max: \", torch.max(testx))\n",
    "print(\"y min: \", torch.min(testy))\n",
    "print(\"y max: \",torch.max(testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1edb3-b3d4-476d-ace0-7202f71014aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a8ccc-b703-4ae8-af39-afd413646501",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader_train))\n",
    "x, y = data\n",
    "print('Shape of x:', x.shape)\n",
    "print('Shape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98557915-f979-4949-b353-bdd1914882e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot input\n",
    "# Plotting the mean of the predictors\n",
    "n_figs = len(x[0,:,0,0])\n",
    "ncols = 4\n",
    "nrows = -(-n_figs // ncols)\n",
    "fig, axes = plt.subplots(figsize=(24, 3.3*nrows), ncols=ncols, nrows=nrows)\n",
    "for i in range(n_figs):\n",
    "    i_row = i // ncols\n",
    "    i_col = i % ncols\n",
    "    if nrows == 1:\n",
    "        ax = axes[i_col]\n",
    "    else:\n",
    "        ax = axes[i_row, i_col]\n",
    "    vals = torch.mean(x[:,i,:,:],axis=0)\n",
    "    plot_map(ax, vals, title=f\"Average of feature {i+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41bdf0-6279-4b81-b669-5194d9edda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the G and D\n",
    "# Adapted from https://github.com/mantariksh/231n_downscaling/blob/master/SRGAN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98a192-f9e0-4a8b-82e2-5080770c9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed46fd-617c-479e-9611-acfa89b6f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS_IN = 4\n",
    "NUM_CHANNELS_OUT = 2\n",
    "dtype = torch.float32 \n",
    "input_size=y.shape[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd69e4c-f581-4897-bff4-673a3d7c27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410a1de-24e3-47ea-b76a-58deb9f9aab4",
   "metadata": {},
   "source": [
    "### Check the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3a5ab-fdb7-4cb7-aef6-188f89634804",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67009b-a7b6-4c1a-a422-a4866545e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = (training_set.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d20d9-f2cf-48a0-8333-c2ec011b8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.unsqueeze(0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173f7ec-28d0-4db4-9cd7-7a341e0cfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator(NUM_CHANNELS_IN, input_size, output_channels=NUM_CHANNELS_OUT)\n",
    "model = model.to(device=device)\n",
    "x = x.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c66a69-f17b-4200-b114-85f085d5dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a339bc-eb38-45af-a2b6-7370db8975e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(x.cpu().detach().numpy()[0, 1, :, :])\n",
    "plt.title(\"Input low-res Precip\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(output.cpu().detach().numpy()[0, 0, :, :])\n",
    "plt.title(\"Output Precip\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd5468-c9e4-48c1-b811-01d2e47e3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121) #??\n",
    "plt.imshow(x.cpu().detach().numpy()[0, 2, :, :])\n",
    "plt.title(\"Input low-res Temp\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(output.cpu().detach().numpy()[0, 1, :, :])\n",
    "plt.title(\"Output Temp\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01be9b-b01e-41cc-b56a-5952e09cc251",
   "metadata": {},
   "source": [
    "### Check the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d64f9c-c88e-46c8-9190-902026568f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = (training_set.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626cf40-48fd-46ca-b9ec-d1c3412e6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da58e15-004d-44a7-909d-5743ffa08ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y.unsqueeze(0)\n",
    "print(y.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2464dea-1526-4b69-8a1b-121b16072990",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = y.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f112def-788e-4a8a-8d9e-dd4864a765e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test the discriminator\n",
    "test_Discriminator(training_set, Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc821d6-2a7f-40d1-8512-b93d7364425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper functions for plotting\n",
    "def plot_epoch(x, y_pred, y):\n",
    "    figsize = (9,4)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(1,3,1) \n",
    "    # x[0,0,..] correspond to topo\n",
    "    plt.imshow(x[0,1,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"Input Precip\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(y_pred[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"Output Precip\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(y[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"True Precip\")\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(x[0,2,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"Input Temp\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(y_pred[0,1,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"Output Temp\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(y[0,1,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"True Temp\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_loss(G_content, G_advers, D_real_L, D_fake_L, weight_param):\n",
    "    \n",
    "    D_count = np.count_nonzero(D_real_L)\n",
    "    G_count = np.count_nonzero(G_content)\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(range(G_count), G_content[range(G_count)])\n",
    "    plt.plot(range(G_count), G_advers[range(G_count)])\n",
    "    plt.plot(range(G_count), G_content[range(G_count)] + weight_param*G_advers[range(G_count)])\n",
    "    plt.legend((\"Content\", \"Adversarial\", \"Total\"))\n",
    "    plt.title(\"Generator loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(range(D_count), D_real_L[range(D_count)])\n",
    "    plt.plot(range(D_count), D_fake_L[range(D_count)])\n",
    "    plt.plot(range(D_count), D_real_L[range(D_count)] + D_fake_L[range(D_count)])\n",
    "    plt.legend((\"Real Pic\", \"Fake Pic\", \"Total\"))\n",
    "    plt.title(\"Discriminator loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b5324-d144-405a-8720-108af1a7db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c9af6-f138-4f04-9038-998b19fabb66",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = Discriminator(num_channels=NUM_CHANNELS_OUT, H=h,W=w) \n",
    "G = Generator(NUM_CHANNELS_IN, input_size, output_channels=NUM_CHANNELS_OUT)\n",
    "\n",
    "lr = 0.0005\n",
    "# No checkpoints....\n",
    "# Define optimizer for discriminator\n",
    "D_solver = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "# Define optimizer for generator\n",
    "G_solver = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c48ecd-11a7-4dfb-ab0f-2f767f4dbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10\n",
    "G_iters=2\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00007085-a261-4a36-a664-99cd9385af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the models to the correct device (GPU if GPU is available)\n",
    "D = D.to(device=device)\n",
    "G = G.to(device=device)\n",
    "    \n",
    "# Put models in training mode\n",
    "D.train()\n",
    "G.train()\n",
    "    \n",
    "#print(\"Expected num iters: \", len(loader_train)*num_epochs)\n",
    "G_content = np.zeros(len(loader_train)*num_epochs*G_iters+1)\n",
    "G_advers = np.zeros(len(loader_train)*num_epochs*G_iters+1)\n",
    "D_real_L = np.zeros(len(loader_train)*num_epochs+1)\n",
    "D_fake_L = np.zeros(len(loader_train)*num_epochs+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc60f5-51d2-42b7-b890-473664e26dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iter_count = 0\n",
    "G_iter_count = 0\n",
    "show_every=40\n",
    "tic = time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for x,y in loader_train:\n",
    "        high_res_imgs = y.to(device=device, dtype=dtype)\n",
    "        logits_real = D(high_res_imgs)\n",
    "\n",
    "        x.requires_grad_()\n",
    "        low_res_imgs = x.to(device=device, dtype=dtype)\n",
    "        fake_images = G(low_res_imgs)\n",
    "        logits_fake = D(fake_images)\n",
    "    \n",
    "        # Update for the discriminator\n",
    "        #d_total_error, D_real_L[iter_count], D_fake_L[iter_count] = discriminator_with_Nan_loss(logits_real, logits_fake)\n",
    "        d_total_error, D_real_L[iter_count], D_fake_L[iter_count] = discriminator_loss(logits_real, logits_fake)\n",
    "        #print('d_total_error:', d_total_error)\n",
    "        #print('D_real_L[iter_count]:', D_real_L[iter_count])\n",
    "        #print('D_fake_L[iter_count]:', D_fake_L[iter_count])\n",
    "        D_solver.zero_grad()\n",
    "        d_total_error.backward()\n",
    "        D_solver.step()\n",
    "        \n",
    "        for i in range(G_iters):\n",
    "                # Update for the generator\n",
    "                fake_images = G(low_res_imgs)\n",
    "                logits_fake = D(fake_images)\n",
    "                gen_logits_fake = D(fake_images)\n",
    "                weight_param = 1e-1 # Weighting put on adversarial loss\n",
    "                g_error, G_content[G_iter_count], G_advers[G_iter_count] = generator_loss(fake_images, high_res_imgs, gen_logits_fake, weight_param=weight_param)\n",
    "                #g_error, G_content[G_iter_count], G_advers[G_iter_count] = generator_withNan_loss(fake_images, high_res_imgs, gen_logits_fake, weight_param=weight_param)\n",
    "                \n",
    "                G_solver.zero_grad()\n",
    "                g_error.backward()\n",
    "                G_solver.step()\n",
    "                G_iter_count += 1\n",
    "                \n",
    "        if (iter_count % show_every == 0):\n",
    "                toc = time()\n",
    "                print('Epoch: {}, Iter: {}, D: {:.4}, G: {:.4}, Time since last print (min): {:.4}'.format(epoch,iter_count,d_total_error.item(),g_error.item(), (toc-tic)/60 ))\n",
    "                tic = time()\n",
    "                plot_epoch(x, fake_images, y)\n",
    "                plot_loss(G_content, G_advers, D_real_L, D_fake_L, weight_param)\n",
    "                print()\n",
    "        iter_count += 1\n",
    "        \n",
    "        \n",
    "        #torch.save(D.cpu().state_dict(), 'GAN_Discriminator_checkpoint_adversWP_1e-1.pt')\n",
    "        #torch.save(G.cpu().state_dict(), 'GAN_Generator_checkpoint_adversWP_1e-1.pt')\n",
    "        \n",
    "        D = D.to(device=device)\n",
    "        G = G.to(device=device)\n",
    "        # Put models in training mode\n",
    "        D.train()\n",
    "        G.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46cecd-cdb0-433d-8779-d914581314ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e00b46-5485-4c51-b277-49b87f101c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
