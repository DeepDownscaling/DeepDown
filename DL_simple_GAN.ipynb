{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721a1923-df03-4ace-a939-8a62df36c1a8",
   "metadata": {},
   "source": [
    "# Precipitation and temperature downscaling using GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a4c7b-f424-4168-87db-fb4c421e81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import yaml\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "from time import time\n",
    "\n",
    "# Import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Config matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=10)\n",
    "mpl.rc('xtick', labelsize=8)\n",
    "mpl.rc('ytick', labelsize=8)\n",
    "\n",
    "# Utils\n",
    "from utils.data_loader import *\n",
    "from utils.utils_plot import *\n",
    "from utils.utils_gans import *\n",
    "\n",
    "# Try dask.distributed and see if the performance improves...\n",
    "from dask.distributed import Client\n",
    "c = Client(n_workers=os.cpu_count()-2, threads_per_worker=1)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"divide by zero encountered in divide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec53edd-fea4-4a06-86cf-9759b3e91883",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cuda Avaliable :\", torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6a454-bf5b-408c-949a-fe32115d6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and constant\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# Paths\n",
    "PATH_DEM = config['PATH_DEM']\n",
    "PATH_ERA5_025 = config['PATH_ERA5_025']  # Original ERA5 0.25°\n",
    "PATH_ERA5_100 = config['PATH_ERA5_100']  # ERA5 1°\n",
    "PATH_MCH = config['PATH_MeteoSwiss']  # Note that Meteoswiss has a different coordinate system, but it doesn't matter here, as we only care about tensors\n",
    "\n",
    "# Data options\n",
    "DATE_START = '1999-01-01'  # '1979-01-01'\n",
    "DATE_END = '2021-12-31'\n",
    "YY_TRAIN = [1999, 2015]  # [1979, 2015]\n",
    "YY_TEST = [2016, 2021]\n",
    "LEVELS = [850,1000] #[300, 500, 700, 850, 1000]  # Available with CORDEX-CMIP6\n",
    "RESOL_LOW = 0.25  # degrees\n",
    "INPUT_VARIABLES = ['tp', 't']\n",
    "INPUT_PATHS = [PATH_ERA5_025 + '/precipitation', PATH_ERA5_025 + '/temperature']\n",
    "DUMP_DATA_TO_PICKLE = True\n",
    "\n",
    "# Crop on a smaller region\n",
    "DO_CROP = True\n",
    "# I reduce the area of crop now, to avoid NA\n",
    "CROP_X = [2700000, 2760000]  # with NAN: [2720000, 2770000]\n",
    "CROP_Y = [1190000, 1260000]  # with NAN: [1290000, 1320000]\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Display options\n",
    "PLOT_DATA_FULL_EXTENT = True\n",
    "PLOT_DATA_CROPPED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd263aa1-8933-46db-bd91-c47d88c5b17b",
   "metadata": {},
   "source": [
    "## Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11a81f-dcc9-4819-b3b0-ad33ea8cf928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target data\n",
    "target = load_target_data(DATE_START, DATE_END, PATH_MCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab299048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the axes of the final target domain based on temperature \n",
    "x_axis = target.TabsD.x\n",
    "y_axis = target.TabsD.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caafee-3bed-4402-bdbf-ac8a4520d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(ax, vals, title=None, vmin=None, vmax=None, cmap=None, show_colorbar=True):\n",
    "    \"\"\" Plotting a map with the provided values.\"\"\"\n",
    "    im = ax.imshow(vals, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    ax.axis('off')\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=12)\n",
    "    if show_colorbar:\n",
    "        plt.colorbar(im, ax=ax, shrink=.5, pad=.05, aspect=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a0efe-4957-4652-87b1-e6c9224e0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_DATA_FULL_EXTENT:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,5))\n",
    "    plot_map(axs[0], target.RhiresD.mean(dim='time').to_numpy().squeeze(), title=\"Daily precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[1], target.TabsD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[2], target.TmaxD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Maximum temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], target.TminD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Minimum temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"target_variables.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e696c2",
   "metadata": {},
   "source": [
    "## Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = load_input_data(DATE_START, DATE_END, PATH_DEM, INPUT_VARIABLES, INPUT_PATHS, \n",
    "                             LEVELS, RESOL_LOW, x_axis, y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53bbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_DATA_FULL_EXTENT:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,4))\n",
    "    plot_map(axs[0], input_data.topo.to_numpy().squeeze(), title=\"Topography\", cmap=mpl.cm.terrain)\n",
    "    plot_map(axs[1], input_data.tp.mean(dim='time').to_numpy().squeeze(), title=\"Input precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[2], input_data.t.sel(level=850).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 850hPa\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], input_data.t.sel(level=1000).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 1000hPa\", cmap=mpl.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68469053-d1f8-4733-ab88-ce5922bcf55d",
   "metadata": {},
   "source": [
    "## Crop domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ff05a-9d5d-436b-bca2-36d9f8d2be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CROP:\n",
    "    input_data = input_data.sel(x=slice(min(CROP_X), max(CROP_X)), y=slice(max(CROP_Y), min(CROP_Y)))\n",
    "    target = target.sel(x=slice(min(CROP_X), max(CROP_X)), y=slice(max(CROP_Y), min(CROP_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee82ad1-2270-4792-9be2-d6b7ab93a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CROP and PLOT_DATA_CROPPED:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,4))\n",
    "    plot_map(axs[0], target.RhiresD.mean(dim='time').to_numpy().squeeze(), title=\"Daily precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[1], target.TabsD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[2], target.TmaxD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Maximum temperature\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], target.TminD.mean(dim='time').to_numpy().squeeze(), title=\"Daily Minimum temperature\", cmap=mpl.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e606d-f05c-4b7a-8ad8-45ba02f58e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CROP and PLOT_DATA_CROPPED:\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(18,4))\n",
    "    plot_map(axs[0], input_data.topo.to_numpy().squeeze(), title=\"Topography\", cmap=mpl.cm.terrain)\n",
    "    plot_map(axs[1], input_data.tp.mean(dim='time').to_numpy().squeeze(), title=\"Input precipitation\", cmap=mpl.cm.YlGnBu)\n",
    "    plot_map(axs[2], input_data.t.sel(level=850).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 850hPa\", cmap=mpl.cm.RdBu_r)\n",
    "    plot_map(axs[3], input_data.t.sel(level=1000).mean(dim='time').to_numpy().squeeze(), title=\"Input temperature at 1000hPa\", cmap=mpl.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e275c8-038a-4012-bb9a-3783af9a0d7d",
   "metadata": {},
   "source": [
    "## Split sample and data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9046d4-1db6-44ba-947b-e82198696de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train = input_data.sel(time=slice('1999', '2011')) \n",
    "x_valid = input_data.sel(time=slice('2012', '2015')) \n",
    "x_test = input_data.sel(time=slice('2016', '2021'))\n",
    "\n",
    "y_train = target.sel(time=slice('1999', '2011'))\n",
    "y_valid = target.sel(time=slice('2012', '2005'))\n",
    "y_test = target.sel(time=slice('2006', '2011'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe836e2-e95d-4540-a7b2-198459a1b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables to use as input and output\n",
    "input_vars = {'topo' : None, 'tp': None, 't': LEVELS}\n",
    "output_vars = ['RhiresD', 'TabsD', 'TmaxD', 'TminD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cde07-f83e-4115-ad6e-a3fa0a8d5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator in pytorch - Adapted from the keras class\n",
    "class DataGenerator(Dataset):\n",
    "    def __init__(self, X, y, input_vars, output_vars, shuffle=True, load=True, mean=None, std=None, tp_log=None):\n",
    "        \"\"\"\n",
    "        Data generator for WeatherBench data.\n",
    "        Template from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "        Args:\n",
    "            X: Dataset containing all input variables\n",
    "            y: Dataset containing the data to predict\n",
    "            input_vars: Dictionary of the form {'var': level}. Use None for level if data is of single level\n",
    "            output_vars: List of variables to be predicted\n",
    "            shuffle: bool. If True, data is shuffled.\n",
    "            load: bool. If True, datadet is loaded into RAM.\n",
    "            mean: If None, compute mean from data.\n",
    "            std: If None, compute standard deviation from data.\n",
    "            tp_log: Log transformation for precipitation. If None, no transformation is applied.\n",
    "        \"\"\"\n",
    "        self.y = y\n",
    "        self.input_vars = input_vars\n",
    "        self.output_vars = output_vars\n",
    "        self.shuffle = shuffle\n",
    "                \n",
    "        data = []\n",
    "        generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "\n",
    "        for var, levels in input_vars.items():\n",
    "            # Variables transformation\n",
    "            if var == 'tp' and tp_log:\n",
    "                X = self.log_trans(X[var], tp_log)\n",
    "\n",
    "            # Handle dimensions\n",
    "            if var == 'topo':\n",
    "                data.append(X[var].expand_dims(\n",
    "                        {'level': generic_level, 'time': X.time}, (1, 0)\n",
    "                    ))\n",
    "            elif levels is None:\n",
    "                data.append(X[var].expand_dims({'level': generic_level}, 1)) \n",
    "            else:\n",
    "                data.append(X[var].sel(level=levels))\n",
    "\n",
    "        # In PyTorch we must transpose (C,H,W,B)\n",
    "        self.X = xr.concat(data, 'level').transpose('level', 'y', 'x', 'time')\n",
    "\n",
    "        # Normalize \n",
    "        self.mean = self.X.mean(('time', 'y', 'x')).compute() if mean is None else mean\n",
    "        self.std  = self.X.mean(('time', 'y', 'x')).compute() if std is None else std\n",
    "        self.X = (self.X - self.mean) / self.std\n",
    "        \n",
    "        # Get indices of samples\n",
    "        self.n_samples = self.X.shape[1]\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        # Prepare the target\n",
    "        self.y = [self.y[var] for var in self.output_vars]\n",
    "\n",
    "        # Concatenate the DataArray objects along a new dimension\n",
    "        self.y = xr.concat(self.y, dim='level').transpose('level', 'y', 'x', 'time')\n",
    "\n",
    "        # For some weird reason calling .load() earlier messes up the mean and std computations\n",
    "        if load: \n",
    "            print('Loading data into RAM')\n",
    "            self.X.load()\n",
    "            self.y.load()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of samples'\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Loads and returns a sample from the dataset'\n",
    "        idxs = self.idxs[idx]\n",
    "        X = (torch.Tensor(self.X.isel(time=idxs).values))\n",
    "        y = (torch.Tensor(self.y.isel(time=idxs).values))\n",
    "        \n",
    "        if y.ndim == 2:\n",
    "            # Expand dimensions\n",
    "            y = torch.unsqueeze(y, dim=0)\n",
    "            \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.idxs = np.arange(self.n_samples)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.idxs)\n",
    "    \n",
    "    def log_trans(x, e):\n",
    "        return np.log(x + e) - np.log(e)\n",
    "\n",
    "    def log_retrans(x, e):\n",
    "        return np.exp(x + np.log(e)) - e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27464664-a9c9-431a-97ec-ff51a8961df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = DataGenerator(x_train, y_train, input_vars, output_vars)\n",
    "loader_train = torch.utils.data.DataLoader(training_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3bcd8-b6f7-4d1d-9fca-42d7ae7b4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "valid_set = DataGenerator(x_valid, y_valid, input_vars, output_vars, mean=training_set.mean, std=training_set.std)\n",
    "loader_val = torch.utils.data.DataLoader(valid_set, batch_size=32)\n",
    "\n",
    "# Test\n",
    "test_set = DataGenerator(x_test, y_test, input_vars, output_vars, mean=training_set.mean, std=training_set.std)\n",
    "loader_test = torch.utils.data.DataLoader(test_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdb8e7-0119-4d6f-a7c9-6266c9db0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure the range on the input and output images is correct, and they're the correct shape\n",
    "testx, testy = training_set.__getitem__(3)\n",
    "print(\"x shape: \", testx.shape)\n",
    "print(\"y shape: \", testy.shape)\n",
    "print(\"x min: \", torch.min(testx))\n",
    "print(\"x max: \", torch.max(testx))\n",
    "print(\"y min: \", torch.min(testy))\n",
    "print(\"y max: \",torch.max(testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a8ccc-b703-4ae8-af39-afd413646501",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader_train))\n",
    "x, y = data\n",
    "print('Shape of x:', x.shape)\n",
    "print('Shape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98557915-f979-4949-b353-bdd1914882e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot input\n",
    "# Plotting the mean of the predictors\n",
    "n_figs = len(x[0,:,0,0])\n",
    "ncols = 4\n",
    "nrows = -(-n_figs // ncols)\n",
    "fig, axes = plt.subplots(figsize=(24, 3.3*nrows), ncols=ncols, nrows=nrows)\n",
    "for i in range(n_figs):\n",
    "    i_row = i // ncols\n",
    "    i_col = i % ncols\n",
    "    if nrows == 1:\n",
    "        ax = axes[i_col]\n",
    "    else:\n",
    "        ax = axes[i_row, i_col]\n",
    "    vals = torch.mean(x[:,i,:,:],axis=0)\n",
    "    plot_map(ax, vals, title=f\"Average of feature {i+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41bdf0-6279-4b81-b669-5194d9edda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the G and D\n",
    "# Adapted from https://github.com/mantariksh/231n_downscaling/blob/master/SRGAN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072e46f-3747-4add-8b90-375d9f7b8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, sampler, TensorDataset\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758b33e-41ea-47a3-ae93-d0ab56fb35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channels, H, W):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=num_channels, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            Flatten(),  \n",
    "            nn.Linear(512 * int(np.ceil(H/16)) * int(np.ceil(W/16)), 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea8d2e-0341-4752-a720-8689ec27b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=3, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(num_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(num_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.layers(x)\n",
    "\n",
    "\n",
    "        \n",
    "class UpscaleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scale_factor):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.PixelShuffle(scale_factor),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_channels, input_size, output_channels =4, num_res_blocks=16, scale_factor=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.input_size = input_size\n",
    "        self.output = output_channels\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.ReflectionPad2d(4),\n",
    "            nn.Conv2d(num_channels, 64, kernel_size=9, stride=1, padding=0),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        self.resBlocks = nn.ModuleList([ResidualBlock(64) for i in range(self.num_res_blocks)])\n",
    "\n",
    "        self.post_resid_conv = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.upscale_blocks = nn.ModuleList()\n",
    "        for _ in range(int(math.log(scale_factor, 2))):\n",
    "            self.upscale_blocks.append(UpscaleBlock(64, 64 * 4, scale_factor=2))\n",
    "\n",
    "        self.conv_prelu = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=0),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    \n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.ReflectionPad2d(4),\n",
    "            nn.Conv2d(64, self.output, 9, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_conv_out = self.initial_conv(x)\n",
    "                \n",
    "        res_block_out = self.resBlocks[0](initial_conv_out)\n",
    "        for i in range(1, self.num_res_blocks):\n",
    "            res_block_out = self.resBlocks[i](res_block_out)\n",
    "\n",
    "        post_resid_conv_out = self.post_resid_conv(res_block_out) + initial_conv_out\n",
    "\n",
    "        upscale_out = post_resid_conv_out\n",
    "        for block in self.upscale_blocks:\n",
    "            upscale_out = block(upscale_out)\n",
    "\n",
    "        conv_prelu_out = self.conv_prelu(upscale_out)\n",
    "        final_out = self.final_conv(conv_prelu_out)\n",
    "        # To get the final desired shape\n",
    "        print(final_out.shape)\n",
    "        final_out = F.interpolate(final_out, size=self.input_size, mode='bicubic', align_corners=True)\n",
    "\n",
    "        return final_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98a192-f9e0-4a8b-82e2-5080770c9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed46fd-617c-479e-9611-acfa89b6f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS_IN = 5\n",
    "dtype = torch.float32 \n",
    "input_size=y.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd69e4c-f581-4897-bff4-673a3d7c27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410a1de-24e3-47ea-b76a-58deb9f9aab4",
   "metadata": {},
   "source": [
    "### Check the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3a5ab-fdb7-4cb7-aef6-188f89634804",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67009b-a7b6-4c1a-a422-a4866545e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = (training_set.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d20d9-f2cf-48a0-8333-c2ec011b8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.unsqueeze(0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173f7ec-28d0-4db4-9cd7-7a341e0cfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator(NUM_CHANNELS_IN,input_size)\n",
    "model = model.to(device=device)\n",
    "x = x.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48112231-61da-422d-8b4a-41720f4cdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c66a69-f17b-4200-b114-85f085d5dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d690128-f07a-4fd6-8531-0e40e9667b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a339bc-eb38-45af-a2b6-7370db8975e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(x.cpu().detach().numpy()[0, 1, :, :])\n",
    "plt.title(\"Input low-res Precip\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(output.cpu().detach().numpy()[0, 0, :, :])\n",
    "plt.title(\"Output Precip\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd5468-c9e4-48c1-b811-01d2e47e3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121) #??\n",
    "plt.imshow(x.cpu().detach().numpy()[0, 2, :, :])\n",
    "plt.title(\"Input low-res Temp\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(output.cpu().detach().numpy()[0, 1, :, :])\n",
    "plt.title(\"Output Temp\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01be9b-b01e-41cc-b56a-5952e09cc251",
   "metadata": {},
   "source": [
    "### Check the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d64f9c-c88e-46c8-9190-902026568f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = (training_set.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626cf40-48fd-46ca-b9ec-d1c3412e6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da58e15-004d-44a7-909d-5743ffa08ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y.unsqueeze(0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2464dea-1526-4b69-8a1b-121b16072990",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = y.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f112def-788e-4a8a-8d9e-dd4864a765e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test the discriminator\n",
    "def test_Discriminator():\n",
    "    x,y = (training_set.__getitem__(3))\n",
    "    y = y.unsqueeze(0)\n",
    "    print(\"y: \", y.shape)\n",
    "    model = Discriminator(num_channels=1, H=h,W=w)\n",
    "    output = model(y)\n",
    "    print(output.size())\n",
    "    print(output)\n",
    "#test_Discriminator()\n",
    "\n",
    "\n",
    "def test_withnan_Discriminator():\n",
    "    x, y = training_set.__getitem__(3)\n",
    "    y = y.unsqueeze(0)\n",
    "    print(\"y shape:\", y.shape)\n",
    "\n",
    "    # Replace NaN values with a valid value\n",
    "    y = torch.where(torch.isnan(y), torch.zeros_like(y), y)\n",
    "\n",
    "    model = Discriminator(num_channels=1, H=h, W=w)\n",
    "    output = model(y)\n",
    "    print(\"Output size:\", output.size())\n",
    "    print(output)\n",
    "\n",
    "test_withnan_Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840c5bb-5267-4285-853d-62991a4b4bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generator_withNan_loss(gen_img, true_img, logits_fake, weight_param=1e-3):\n",
    "    \"\"\"\n",
    "    Computes the generator loss described above.\n",
    "\n",
    "    Inputs:\n",
    "    - gen_img: (PyTorch tensor) shape N, C image generated by the Generator, so that we can calculate MSE\n",
    "    - true_img: (PyTorch tensor) the true, high res image, so that we can calculate the MSE\n",
    "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
    "    - weight_param: how much to weight the adversarial loss by when summing the losses. Default in Ledig paper is 1e-3\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Tensor containing the (scalar) loss for the generator.\n",
    "    \"\"\"\n",
    "    #\n",
    "    if torch.isnan(gen_img).any() or torch.isnan(true_img).any() or torch.isnan(logits_fake).any():\n",
    "        # Handle NaN values here\n",
    "        # Replace NaN values in gen_img and true_img with zeros\n",
    "        gen_img = torch.where(torch.isnan(gen_img), torch.zeros_like(gen_img), gen_img)\n",
    "        true_img = torch.where(torch.isnan(true_img), torch.zeros_like(true_img), true_img)\n",
    "\n",
    "    \n",
    "    # Content loss - MSE loss\n",
    "    content_loss_func = nn.MSELoss()\n",
    "    content_loss = content_loss_func(gen_img, true_img)\n",
    "        \n",
    "    N = logits_fake.shape[0]\n",
    "    desired_labels = torch.ones(N, 1).to(device=device, dtype=dtype)\n",
    "    BCE_Loss = nn.BCELoss()\n",
    "    adversarial_loss = BCE_Loss(logits_fake, desired_labels)\n",
    "    \n",
    "    total_loss = content_loss + weight_param * adversarial_loss\n",
    "    \n",
    "    return total_loss, content_loss, adversarial_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42260d7a-54bd-4dab-96d4-5748d8412470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generator_withNaN_loss(gen_img, true_img, logits_fake, weight_param=1e-3):\n",
    "    \"\"\"\n",
    "    Computes the generator loss described above.\n",
    "\n",
    "    Inputs:\n",
    "    - gen_img: (PyTorch tensor) shape N, C image generated by the Generator, so that we can calculate MSE\n",
    "    - true_img: (PyTorch tensor) the true, high res image, so that we can calculate the MSE\n",
    "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
    "    - weight_param: how much to weight the adversarial loss by when summing the losses. Default in Ledig paper is 1e-3\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Tensor containing the (scalar) loss for the generator.\n",
    "    \"\"\"\n",
    "    # Handle NaN values in gen_img and true_img\n",
    "    gen_img = torch.where(torch.isnan(gen_img), torch.zeros_like(gen_img), gen_img)\n",
    "    true_img = torch.where(torch.isnan(true_img), torch.zeros_like(true_img), true_img)\n",
    "    \n",
    "    # Content loss - MSE loss\n",
    "    content_loss_func = nn.MSELoss()\n",
    "    content_loss = content_loss_func(gen_img, true_img)\n",
    "        \n",
    "    N = logits_fake.shape[0]\n",
    "    desired_labels = torch.ones(N, 1).to(device=device, dtype=dtype)\n",
    "    BCE_Loss = nn.BCELoss()\n",
    "    adversarial_loss = BCE_Loss(logits_fake, desired_labels)\n",
    "    \n",
    "    total_loss = content_loss + weight_param * adversarial_loss\n",
    "    \n",
    "    return total_loss, content_loss, adversarial_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0a5c4-1d76-4580-bfa1-2ba919a286d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_with_Nan_loss(logits_real, logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the discriminator loss described above.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: PyTorch Tensor of shape (N,) giving scores for the real data (real numbers). \n",
    "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data (real numbers).\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Tensor containing the loss for the discriminator.\n",
    "    \"\"\"\n",
    "    # Handle NaN values\n",
    "    if torch.isnan(logits_real).any() or torch.isnan(logits_fake).any():\n",
    "        # Replace NaN values with zeros\n",
    "        logits_real = torch.where(torch.isnan(logits_real), torch.zeros_like(logits_real), logits_real)\n",
    "        logits_fake = torch.where(torch.isnan(logits_fake), torch.zeros_like(logits_fake), logits_fake)\n",
    "\n",
    "    N = logits_real.shape[0]\n",
    "    real_labels = torch.ones(N, 1).to(device=logits_real.device, dtype=logits_real.dtype)\n",
    "    fake_labels = torch.zeros(N, 1).to(device=logits_fake.device, dtype=logits_fake.dtype)\n",
    "    \n",
    "    BCE_Loss = nn.BCELoss()\n",
    "    L1 = BCE_Loss(logits_real, real_labels)\n",
    "    L2 = BCE_Loss(logits_fake, fake_labels)\n",
    "    \n",
    "    loss = L1 + L2\n",
    "    return loss, L1, L2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f2223-2d61-4c4f-b1e0-8d89ccfd7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def check_generator_with_nan_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    count, rmse_precip_ypred, rmse_precip_x = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            model = model.to(device=device)\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            \n",
    "            x_np = x.numpy()\n",
    "            x_min = np.amin(x_np, axis=(2,3))[:, :, np.newaxis, np.newaxis]\n",
    "            x_max = np.amax(x_np, axis=(2,3))[:, :, np.newaxis, np.newaxis]\n",
    "            is_nan = np.int((x_min == x_max).any())\n",
    "            eps = 1e-9\n",
    "            x_norm_np = (x_np - x_min) / ((x_max - x_min + is_nan*eps) / 2) - 1\n",
    "            x_norm_np[np.isnan(x_norm_np)] = 0  # Replace NaN values with zeros\n",
    "            \n",
    "            x_norm = torch.from_numpy(x_norm_np)\n",
    "            x_norm = x_norm.to(device=device, dtype=dtype)\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            \n",
    "            y_predicted = model(x)\n",
    "            y_predicted[np.isnan(y_predicted)] = 0  # Replace NaN values with zeros\n",
    "            \n",
    "            rmse_precip_ypred += torch.sqrt(torch.mean((y_predicted[:,0,:,:]-y[:,0,:,:]).pow(2)))\n",
    "            rmse_precip_x += torch.sqrt(torch.mean((x_norm[:,0,:,:]-y[:,0,:,:]).pow(2)))\n",
    "            count += 1\n",
    "            \n",
    "        rmse_precip_ypred /= count\n",
    "        rmse_precip_x /= count\n",
    "        print('RMSEs: \\tInput precip: %.3f\\n\\tOutput precip: %.3f\\n\\t' % \n",
    "              (rmse_precip_x, rmse_precip_ypred))\n",
    "        \n",
    "        \n",
    "def check_discriminator_with_nan_accuracy(loader, D, G):\n",
    "    D = D.to(device=device)\n",
    "    G = G.to(device=device)\n",
    "    D.eval()\n",
    "    G.eval()\n",
    "    \n",
    "    count, avg_true_pred, avg_fake_pred = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            \n",
    "            true_pred = D(y)\n",
    "            true_pred[np.isnan(true_pred)] = 0  # Replace NaN values with zeros\n",
    "            avg_true_pred += true_pred.sum()\n",
    "            count += len(true_pred)\n",
    "            \n",
    "            fake_imgs = G(x)\n",
    "            fake_pred = D(fake_imgs)\n",
    "            fake_pred[np.isnan(fake_pred)] = 0  # Replace NaN values with zeros\n",
    "            avg_fake_pred += fake_pred.sum()\n",
    "            \n",
    "        avg_true_pred /= count\n",
    "        avg_fake_pred /= count\n",
    "        print(\"Average prediction score on real data: %f\" % (avg_true_pred))\n",
    "        print(\"Average prediction score on fake data: %f\" % (avg_fake_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc821d6-2a7f-40d1-8512-b93d7364425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper functions for plotting\n",
    "def plot_epoch(x, y_pred, y):\n",
    "    figsize = (9,4)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(x[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"Input Precip\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(y_pred[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"Output Precip\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(y[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.title(\"True Precip\")\n",
    "    \n",
    "    \n",
    "def plot_loss(G_content, G_advers, D_real_L, D_fake_L, weight_param):\n",
    "    \n",
    "    D_count = np.count_nonzero(D_real_L)\n",
    "    G_count = np.count_nonzero(G_content)\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(range(G_count), G_content[range(G_count)])\n",
    "    plt.plot(range(G_count), G_advers[range(G_count)])\n",
    "    plt.plot(range(G_count), G_content[range(G_count)] + weight_param*G_advers[range(G_count)])\n",
    "    plt.legend((\"Content\", \"Adversarial\", \"Total\"))\n",
    "    plt.title(\"Generator loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(range(D_count), D_real_L[range(D_count)])\n",
    "    plt.plot(range(D_count), D_fake_L[range(D_count)])\n",
    "    plt.plot(range(D_count), D_real_L[range(D_count)] + D_fake_L[range(D_count)])\n",
    "    plt.legend((\"Real Pic\", \"Fake Pic\", \"Total\"))\n",
    "    plt.title(\"Discriminator loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b5324-d144-405a-8720-108af1a7db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c9af6-f138-4f04-9038-998b19fabb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(num_channels=1, H=h,W=w) \n",
    "G = Generator(NUM_CHANNELS_IN, input_size)\n",
    "\n",
    "lr = 0.0002\n",
    "# No checkpoints....\n",
    "# Define optimizer for discriminator\n",
    "D_solver = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "# Define optimizer for generator\n",
    "G_solver = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c48ecd-11a7-4dfb-ab0f-2f767f4dbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=2\n",
    "G_iters=1\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00007085-a261-4a36-a664-99cd9385af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the models to the correct device (GPU if GPU is available)\n",
    "D = D.to(device=device)\n",
    "G = G.to(device=device)\n",
    "    \n",
    "# Put models in training mode\n",
    "D.train()\n",
    "G.train()\n",
    "    \n",
    "print(\"Expected num iters: \", len(loader_train)*num_epochs)\n",
    "G_content = np.zeros(len(loader_train)*num_epochs*G_iters+1)\n",
    "G_advers = np.zeros(len(loader_train)*num_epochs*G_iters+1)\n",
    "D_real_L = np.zeros(len(loader_train)*num_epochs+1)\n",
    "D_fake_L = np.zeros(len(loader_train)*num_epochs+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d19042-34c7-45c5-9d64-9168a7992a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#high_res_imgs = y.to(device=device, dtype=dtype)\n",
    "#logits_real = D(high_res_imgs)\n",
    "\n",
    "#x.requires_grad_()\n",
    "#low_res_imgs = x.to(device=device, dtype=dtype)\n",
    "#fake_images = G(low_res_imgs)\n",
    "#logits_fake = D(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b65f1d-2a84-42bf-8fe3-9af68eee852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea10af9-ccdd-480e-9296-f8b1f29df472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce0424-de72-4d91-a26d-dd5cf5ba4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_total_error, D_real_L[iter_count], D_fake_L[iter_count] = discriminator_loss(logits_real, logits_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495abff-e819-496f-a6b6-ce2d0a16a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator_loss(logits_real, logits_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f350c36-4da1-40af-98bb-d543a3d46a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################TEST\n",
    "#iter_count = 0\n",
    "#G_iter_count = 0\n",
    "#show_every=40\n",
    "#tic = time()\n",
    "#for epoch in range(num_epochs):\n",
    "#    for x,y in loader_train:\n",
    "#        high_res_imgs = y.to(device=device, dtype=dtype)\n",
    "#        logits_real = D(high_res_imgs)\n",
    "\n",
    "#       x.requires_grad_()\n",
    "#        low_res_imgs = x.to(device=device, dtype=dtype)\n",
    "#        fake_images = G(low_res_imgs)\n",
    "#        logits_fake = D(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fddc3-dff7-47f3-b58b-78423e8f1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_total_error, D_real_L[iter_count], D_fake_L[iter_count] = discriminator_with_Nan_loss(logits_real, logits_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc60f5-51d2-42b7-b890-473664e26dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iter_count = 0\n",
    "G_iter_count = 0\n",
    "show_every=40\n",
    "tic = time()\n",
    "for epoch in range(num_epochs):\n",
    "    for x,y in loader_train:\n",
    "        high_res_imgs = y.to(device=device, dtype=dtype)\n",
    "        logits_real = D(high_res_imgs)\n",
    "\n",
    "        x.requires_grad_()\n",
    "        low_res_imgs = x.to(device=device, dtype=dtype)\n",
    "        fake_images = G(low_res_imgs)\n",
    "        logits_fake = D(fake_images)\n",
    "    \n",
    "        # Update for the discriminator\n",
    "        #d_total_error, D_real_L[iter_count], D_fake_L[iter_count] = discriminator_with_Nan_loss(logits_real, logits_fake)\n",
    "        d_total_error, D_real_L[iter_count], D_fake_L[iter_count] = discriminator_loss(logits_real, logits_fake)\n",
    "        #print('d_total_error:', d_total_error)\n",
    "        #print('D_real_L[iter_count]:', D_real_L[iter_count])\n",
    "        #print('D_fake_L[iter_count]:', D_fake_L[iter_count])\n",
    "        D_solver.zero_grad()\n",
    "        d_total_error.backward()\n",
    "        D_solver.step()\n",
    "        \n",
    "        for i in range(G_iters):\n",
    "                # Update for the generator\n",
    "                fake_images = G(low_res_imgs)\n",
    "                logits_fake = D(fake_images)\n",
    "                gen_logits_fake = D(fake_images)\n",
    "                weight_param = 1e-1 # Weighting put on adversarial loss\n",
    "                g_error, G_content[G_iter_count], G_advers[G_iter_count] = generator_loss(fake_images, high_res_imgs, gen_logits_fake, weight_param=weight_param)\n",
    "                #g_error, G_content[G_iter_count], G_advers[G_iter_count] = generator_withNan_loss(fake_images, high_res_imgs, gen_logits_fake, weight_param=weight_param)\n",
    "                \n",
    "                G_solver.zero_grad()\n",
    "                g_error.backward()\n",
    "                G_solver.step()\n",
    "                G_iter_count += 1\n",
    "                \n",
    "        if (iter_count % show_every == 0):\n",
    "                toc = time()\n",
    "                print('Epoch: {}, Iter: {}, D: {:.4}, G: {:.4}, Time since last print (min): {:.4}'.format(epoch,iter_count,d_total_error.item(),g_error.item(), (toc-tic)/60 ))\n",
    "                tic = time()\n",
    "                plot_epoch(x, fake_images, y)\n",
    "                plot_loss(G_content, G_advers, D_real_L, D_fake_L, weight_param)\n",
    "                print()\n",
    "        iter_count += 1\n",
    "        \n",
    "        D = D.to(device=device)\n",
    "        G = G.to(device=device)\n",
    "        # Put models in training mode\n",
    "        D.train()\n",
    "        G.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46cecd-cdb0-433d-8779-d914581314ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e00b46-5485-4c51-b277-49b87f101c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
